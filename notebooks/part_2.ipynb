{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f91a4c0",
   "metadata": {},
   "source": [
    "# Bridging Neural Dynamics: extending TRFs - Part 2 \n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/Hugo-W/CNSP25_tutorial_HWeissbart/main/)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Hugo-W/CNSP25_tutorial_HWeissbart/blob/main/notebooks/part_2.ipynb)\n",
    "\n",
    "\n",
    "This time let's load some real MEG data and try our freshly designed feature-based Phase-Amplitude Coupling extraction. If time allows, will move onto trying to disentangle brain response to acoustic edges around uncertain vs more certain words, to see whether top-down linguistic information affects lower level envelope tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e3fd99",
   "metadata": {},
   "source": [
    "### Setup (Google Colab only)\n",
    "\n",
    "> We need an extra step to make sure widgets can work in Collab notebooks, uncomment and run the cell bellow if using Google Collab, otherwise just skip this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc2815",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab # type: ignore\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    %pip install -q ipywidgets ipympl\n",
    "    %pip install -q natmeeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc02e0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if IN_COLAB and 'natmeeg' not in sys.modules:\n",
    "    print(\"ğŸ” Restarting kernel to use newly installed packages...\")\n",
    "    get_ipython().kernel.do_shutdown(True) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec3b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download `utils`\n",
    "if IN_COLAB:\n",
    "    import requests\n",
    "    import os\n",
    "\n",
    "    files = ['__init__.py', 'helpers.py', 'surrogate.py', 'visu.py', 'utils.py']\n",
    "    # Create utils directory if it doesn't exist\n",
    "    os.makedirs('utils', exist_ok=True)\n",
    "    for f in files:\n",
    "        url = f'https://raw.githubusercontent.com/Hugo-W/CNSP25_tutorial_HWeissbart/main/utils/{f}'\n",
    "        response = requests.get(url)\n",
    "\n",
    "        with open(f'utils/{f}', 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "    from google.colab import output # type: ignore\n",
    "    output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ea8ec5",
   "metadata": {},
   "source": [
    "## Imports and Data download\n",
    "\n",
    "First let's get all the libraries, data and path setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f075932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import VBox, HBox, HTML, HTMLMath, Checkbox, FloatSlider, IntSlider, Dropdown, interact, Button\n",
    "import tqdm.notebook as tqdm\n",
    "import sys, os\n",
    "# Add utils to Python path\n",
    "sys.path.append('..') # access to utils.py and visu.py modules\n",
    "from utils.utils import download_file, list_h5_data\n",
    "from utils.visu import plot_fft\n",
    "from utils.surrogate import (simulate_background_eeg, simulate_spike_events,\n",
    "                             simulate_smooth_signal, create_kernel)\n",
    "from utils.helpers import lowpass_filter, convolve_with_kernel, lag_matrix, lag_span, _svd_regress, svd_trf_estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df36835",
   "metadata": {},
   "source": [
    "The cell below will download the data if they are not already present in the `data/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3196ab0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " âœ… File audioBook-filtered-ICAed-raw.fif already exists in the ../data/sub-001 directory.\n",
      " âœ… File audioBook-eve.fif already exists in the ../data/sub-001 directory.\n",
      " âœ… File noise-cov.fif already exists in the ../data/sub-001 directory.\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/\"\n",
    "files = {\n",
    "    \"sub-001/audioBook-filtered-ICAed-raw.fif\": \"https://osf.io/download/689ca8ab66c0f8121bd5a0fd/\",\n",
    "    \"sub-001/audioBook-eve.fif\": \"https://osf.io/download/d7phu/\",\n",
    "    \"sub-001/noise-cov.fif\": \"https://osf.io/download/689ca6fa89cdf5804c13c704/\",\n",
    "    \"stim/predictors.hdf5\": \"https://osf.io/download/68b3114c95a919eba5fe1c79/\"\n",
    "}\n",
    "# Bad channels: MLF12, MRC55, MRF61\n",
    "\n",
    "for file_name, url in files.items():\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    # Check if the data directory exists, if not create it\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"{file_name} not found. Downloading... (this operation may take a couple of minutes depending on your connection)\")\n",
    "        download_file(url, file_path)\n",
    "    else:\n",
    "        print(f\" âœ… File {file_name} already exists in the {data_dir} directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ed185b",
   "metadata": {},
   "source": [
    "Let's have a look into the HDF5 file of stimulus features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426976f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcripts_v2\n",
      "â”œâ”€â”€ 100\n",
      "â”‚   â”œâ”€â”€ acoustic\n",
      "â”‚   â”‚   â”œâ”€â”€ ANGE_part1_normalized (27402,)\n",
      "â”‚   â”‚   â”œâ”€â”€ Anderson_S01_P01_normalized (29800,)\n",
      "â”‚   â”‚   â”œâ”€â”€ Anderson_S01_P02_normalized (31770,)\n",
      "â”‚   â”‚   â”œâ”€â”€ Anderson_S01_P03_normalized (28900,)\n",
      "â”‚   â”‚   â”œâ”€â”€ Anderson_S01_P04_normalized (35080,)\n",
      "â”‚   â”‚   â”œâ”€â”€ BALL_part1_normalized (29801,)\n",
      "â”‚   â”‚   â”œâ”€â”€ EAUV_part1_normalized (34382,)\n",
      "â”‚   â”‚   â”œâ”€â”€ EAUV_part2_normalized (36153,)\n",
      "â”‚   â”‚   â”œâ”€â”€ grimm_20_1_normalized (36659,)\n",
      "â”‚   â”‚   â”œâ”€â”€ grimm_20_2_normalized (40055,)\n",
      "â”‚   â”‚   â”œâ”€â”€ grimm_23_1_normalized (30309,)\n",
      "â”‚   â”‚   â”œâ”€â”€ grimm_23_2_normalized (33287,)\n",
      "â”‚   â”‚   â”œâ”€â”€ grimm_23_3_normalized (30292,)\n",
      "â”‚   â”œâ”€â”€ wordlevel\n",
      "â”‚   â”‚   â”œâ”€â”€ ANGE_part1_normalized (27402, 9)\n",
      "â”‚   â”‚   â”œâ”€â”€ Anderson_S01_P01_normalized (29800, 9)\n",
      "â”‚   â”‚   â”œâ”€â”€ Anderson_S01_P02_normalized (31770, 9)\n",
      "â”‚   â”‚   â”œâ”€â”€ Anderson_S01_P03_normalized (28900, 9)\n",
      "â”‚   â”‚   â”œâ”€â”€ Anderson_S01_P04_normalized (35080, 9)\n",
      "â”‚   â”‚   â”œâ”€â”€ BALL_part1_normalized (29801, 9)\n",
      "â”‚   â”‚   â”œâ”€â”€ EAUV_part1_normalized (34382, 9)\n",
      "â”‚   â”‚   â”œâ”€â”€ EAUV_part2_normalized (36153, 9)\n",
      "â”‚   â”‚   â”œâ”€â”€ grimm_20_1_normalized (36659, 9)\n",
      "â”‚   â”‚   â”œâ”€â”€ grimm_20_2_normalized (40055, 9)\n",
      "â”‚   â”‚   â”œâ”€â”€ grimm_23_1_normalized (30309, 9)\n",
      "â”‚   â”‚   â”œâ”€â”€ grimm_23_2_normalized (33287, 9)\n",
      "â”‚   â”‚   â”œâ”€â”€ grimm_23_3_normalized (30292, 9)\n"
     ]
    }
   ],
   "source": [
    "list_h5_data(\"../data/stim/predictors.hdf5\", max_depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eca2d8",
   "metadata": {},
   "source": [
    "We can see that the stimulus feature file `predictors.hdf5` contains a matrix of feature per story, organised under two keys: `acoustic` and `wordlevel`. The former contains the smooth continuous feature (only envelop here), while the latter contains impulse-like time series of word-level features. \n",
    "\n",
    "We can also observe that word level features are matrices with 9 columns. These map to the following features:\n",
    "- Word Onsets\n",
    "- Word frequency\n",
    "- Surprisal\n",
    "- Entropy\n",
    "- KL divergence\n",
    "- Prediction error (surprisal weighted by precision, with precision ~1/entropy)\n",
    "- Depth\n",
    "- Close\n",
    "- Open"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
